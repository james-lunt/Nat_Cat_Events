{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ebadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter warnings for readability\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5f2a6",
   "metadata": {},
   "source": [
    "Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd5d83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "W0708 23:00:30.259000 55984 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, Trainer, TrainingArguments,AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import spacy\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47fbe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA version PyTorch was built with: 11.8\n",
      "Is CUDA available: True\n",
      "CUDA device: Quadro P2000 with Max-Q Design\n",
      "GPU Opt:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version PyTorch was built with:\", torch.version.cuda)\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU Opt: \", config['use_available_gpus'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e65520",
   "metadata": {},
   "source": [
    "Read in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2effe2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv('Nat Cat Events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb1bcb",
   "metadata": {},
   "source": [
    "Only Consider Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06c5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = events_df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23eb98",
   "metadata": {},
   "source": [
    "### __Step 1__: Remove *duplicates*, *null values* & *whitespaces*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf90211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7802fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = titles.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab14738",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = pd.DataFrame(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b21fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df[\"title\"] = titles_df[\"title\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb359743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65158 entries, 0 to 65157\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   65158 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 509.2+ KB\n"
     ]
    }
   ],
   "source": [
    "titles_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe02fd",
   "metadata": {},
   "source": [
    "### __Step 2__: Find articles containing a *location*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a45df",
   "metadata": {},
   "source": [
    "Select NLP Pipeline depending on hardware availability\n",
    "\n",
    "\n",
    "`en_core_web_try`: Uses a Transformer for word & context embeddings\n",
    "\n",
    "\n",
    "`en_core_web_sm`: Token-to-Vector (Tok2Vec) based pipeline uses CNN's or LSTM's for work & context embeddings\n",
    "\n",
    "See documentation [here](https://spacy.io/models/en#benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e715c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using trf (GPU Supported)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and config['use_available_gpus']:\n",
    "    spacy.require_gpu() # Use GPU\n",
    "    nlp = spacy.load(config['ner_pipeline_gpu'])\n",
    "    batch_size = config['batch_size_gpu']\n",
    "    print(\"Using trf (GPU Supported)\")\n",
    "else:\n",
    "    nlp = spacy.load(config['ner_pipeline_cpu']) # Use CPU\n",
    "    batch_size = config['batch_size_cpu']\n",
    "    print(\"Using sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8736b",
   "metadata": {},
   "source": [
    "##### Find articles where the titles match the following criteria using *SpaCy* a *NLP* module for *Named-Entity-Recognition*\n",
    "- Contains a geopolitical entity like a country, city or state (Entity GPE) OR\n",
    "- Contains a Non-GPE location like a mountain or body of water (Entity LOC)\n",
    "\n",
    "Entities are taken from the [OntoNotes5](https://catalog.ldc.upenn.edu/LDC2013T19) dataset which many english models are built on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95afca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(titles_df['title'].values, batch_size=batch_siz))\n",
    "#titles_df['occurrence_and_location'] = [any(ent.label_ in (\"DATE\", \"TIME\") for ent in doc.ents) and any(ent.label_ in (\"GPE\", \"LOC\") for ent in doc.ents) for doc in docs]\n",
    "titles_df['has_location'] = [any(ent.label_ in (\"GPE\", \"LOC\") for ent in doc.ents) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up CUDA Cores\n",
    "if config['use_available_gpus']:\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edabd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.to_csv('titles_containing_locations.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f8df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = pd.read_csv('titles_containing_locations.csv')\n",
    "titles_location_df = titles_df[titles_df['has_location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386d6695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40989 entries, 0 to 65156\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         40989 non-null  object\n",
      " 1   has_location  40989 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 680.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titles_location_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba87317",
   "metadata": {},
   "source": [
    "### __Step 3__: Use a *Zero-Shot-Classifier* to capture confidence of a title implying a *natural catastrophe event*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d5c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "labels = [\"natural catastrophe event that has occurred\"]\n",
    "\n",
    "if torch.cuda.is_available() and config['use_available_gpus']:\n",
    "    print(\"Using GPU\")\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=config['zero_shot_model_gpu'], device=0) # Use GPU\n",
    "    results = classifier(titles_location_df['title'].tolist(), candidate_labels=labels, batch_size=config['batch_size_gpu'])\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=config['zero_shot_model_cpu'], device=-1) # Use CPU\n",
    "    results = classifier(titles_location_df['title'].tolist(), candidate_labels=labels, batch_size=config['batch_size_cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_location_df['zero_shot_score'] = [zero_shot['scores'][0] for zero_shot in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0540ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_location_df.to_csv('titles_zero_shot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf93def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up CUDA Cores\n",
    "del classifier\n",
    "del results\n",
    "if config['use_available_gpus']:\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f6c09",
   "metadata": {},
   "source": [
    "#### Analyse the Distribution of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_location_df['zero_shot_score'].hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
